{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unset PYTHONPATH first\n",
    "from ko_text import *\n",
    "from ko_crawler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = NLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.read_csv('Data/meta_morphs_final.csv', encoding = 'utf-8')\n",
    "\n",
    "# 용량을 줄이기 위해 '단어 단어' 꼴로 묶어둔 token을 ['단어', '단어'] 꼴로 풀기\n",
    "token_df['Token'] = [token.split() for token in token_df['Token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Text</th>\n",
       "      <th>Token</th>\n",
       "      <th>Num of Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>financial</td>\n",
       "      <td>\\n\\n\\n텀블벅에서 크라우드 펀딩이 이뤄지고 있는 `아침달 시집`.\\n\\n    ...</td>\n",
       "      <td>[텀블벅, 크라, 우드, 펀딩, 이뤄지고, 아침, 시집, 많지, 않은, 금액, 으로...</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>economy</td>\n",
       "      <td>\\n\\n\\n[사진 제공: 연합뉴스]\\n\\n                     유류...</td>\n",
       "      <td>[유류, 인하, 국제, 유가, 급락, 입어, 국내, 휘발유, 경유, 하락, 특히, ...</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financial</td>\n",
       "      <td>부득이한 사정으로 매월 내는 보험료가 부담이 될 때 계약은 그대로 유지하면서 보험...</td>\n",
       "      <td>[부득이, 사정, 매월, 내는, 보험료, 부담, 계약, 그대로, 유지, 보험료, 부...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estate</td>\n",
       "      <td>한때 `미분양의 늪`으로 통하던 경기도 파주시 부동산 시장이 달라지고 있다. 지난해...</td>\n",
       "      <td>[한때, 미분, 하던, 경기도, 파주시, 부동산, 시장, 달라지고, 분양, 파주, ...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economy</td>\n",
       "      <td>\\n\\n\\n인디고뱅크의 `미키인서울` 컬래버 맨투맨  &lt;사진제공=월트디즈니코리아&gt;\\...</td>\n",
       "      <td>[인디고, 뱅크, 미키, 서울, 컬래버, 투맨, 월트디즈니, 사의, 마스코트, 미키...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Section                                               Text  \\\n",
       "0  financial  \\n\\n\\n텀블벅에서 크라우드 펀딩이 이뤄지고 있는 `아침달 시집`.\\n\\n    ...   \n",
       "1    economy  \\n\\n\\n[사진 제공: 연합뉴스]\\n\\n                     유류...   \n",
       "2  financial   부득이한 사정으로 매월 내는 보험료가 부담이 될 때 계약은 그대로 유지하면서 보험...   \n",
       "3     estate  한때 `미분양의 늪`으로 통하던 경기도 파주시 부동산 시장이 달라지고 있다. 지난해...   \n",
       "4    economy  \\n\\n\\n인디고뱅크의 `미키인서울` 컬래버 맨투맨  <사진제공=월트디즈니코리아>\\...   \n",
       "\n",
       "                                               Token  Num of Tokens  \n",
       "0  [텀블벅, 크라, 우드, 펀딩, 이뤄지고, 아침, 시집, 많지, 않은, 금액, 으로...            263  \n",
       "1  [유류, 인하, 국제, 유가, 급락, 입어, 국내, 휘발유, 경유, 하락, 특히, ...            166  \n",
       "2  [부득이, 사정, 매월, 내는, 보험료, 부담, 계약, 그대로, 유지, 보험료, 부...            314  \n",
       "3  [한때, 미분, 하던, 경기도, 파주시, 부동산, 시장, 달라지고, 분양, 파주, ...            165  \n",
       "4  [인디고, 뱅크, 미키, 서울, 컬래버, 투맨, 월트디즈니, 사의, 마스코트, 미키...            196  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41418, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(token_df) * 0.8)\n",
    "np.random.seed(0)\n",
    "train_index_ls = np.random.choice(token_df.index, train_size, replace = False)\n",
    "test_index_ls = [x for x in token_df.index if not x in train_index_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33134, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = token_df.loc[train_index_ls]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8284, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = token_df.loc[test_index_ls]\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bio & tech': 1739,\n",
       "         'business': 4863,\n",
       "         'culture & art': 4102,\n",
       "         'economy': 2608,\n",
       "         'estate': 3932,\n",
       "         'financial': 746,\n",
       "         'it': 1742,\n",
       "         'politics': 3775,\n",
       "         'society': 3356,\n",
       "         'stock': 2508,\n",
       "         'world': 3763})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df['Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bio & tech': 419,\n",
       "         'business': 1220,\n",
       "         'culture & art': 1039,\n",
       "         'economy': 613,\n",
       "         'estate': 977,\n",
       "         'financial': 181,\n",
       "         'it': 419,\n",
       "         'politics': 903,\n",
       "         'society': 873,\n",
       "         'stock': 665,\n",
       "         'world': 975})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_df['Section'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sampling for training classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 label마다 학습할 단어의 수\n",
    "train_batch_size = 1000\n",
    "test_batch_size = 100\n",
    "\n",
    "train_token_ls_split, train_tag_ls_split = nlp.oversample_batch(train_df['Token'], train_df['Section'], train_batch_size)\n",
    "test_token_ls_split, test_tag_ls_split =  nlp.undersample_batch(test_df['Token'],test_df['Section'], test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'bio & tech': 1000,\n",
       "         'business': 1000,\n",
       "         'culture & art': 1000,\n",
       "         'economy': 1000,\n",
       "         'estate': 1000,\n",
       "         'financial': 1000,\n",
       "         'it': 1000,\n",
       "         'politics': 1000,\n",
       "         'society': 1000,\n",
       "         'stock': 1000,\n",
       "         'world': 1000})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_token_ls_split))\n",
    "Counter(train_tag_ls_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잘 뽑혔는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(train_token_ls_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tag_ls_split[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec Parameter 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **set ALPHA as default**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ls = train_df['Token'].tolist() + test_df['Token'].tolist()\n",
    "label_ls = train_df['Section'].tolist() + test_df['Section'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41418, 41418)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_ls), len(label_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 16:11:03,748 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-12-04 16:11:03,807 : INFO : collecting all words and their counts\n",
      "2018-12-04 16:11:03,808 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-12-04 16:11:04,140 : INFO : PROGRESS: at example #10000, processed 1884311 words (5681463/s), 81597 word types, 11 tags\n",
      "2018-12-04 16:11:04,486 : INFO : PROGRESS: at example #20000, processed 3762527 words (5436144/s), 110172 word types, 11 tags\n",
      "2018-12-04 16:11:04,875 : INFO : PROGRESS: at example #30000, processed 5590210 words (4711053/s), 130122 word types, 11 tags\n",
      "2018-12-04 16:11:05,223 : INFO : PROGRESS: at example #40000, processed 7430810 words (5298256/s), 143472 word types, 11 tags\n",
      "2018-12-04 16:11:05,287 : INFO : collected 148759 word types and 11 unique tags from a corpus of 41418 examples and 7723626 words\n",
      "2018-12-04 16:11:05,287 : INFO : Loading a fresh vocabulary\n",
      "2018-12-04 16:11:06,064 : INFO : effective_min_count=1 retains 148759 unique words (100% of original 148759, drops 0)\n",
      "2018-12-04 16:11:06,064 : INFO : effective_min_count=1 leaves 7723626 word corpus (100% of original 7723626, drops 0)\n",
      "2018-12-04 16:11:06,430 : INFO : deleting the raw counts dictionary of 148759 items\n",
      "2018-12-04 16:11:06,434 : INFO : sample=0.0001 downsamples 715 most-common words\n",
      "2018-12-04 16:11:06,435 : INFO : downsampling leaves estimated 6315301 word corpus (81.8% of prior 7723626)\n",
      "2018-12-04 16:11:06,998 : INFO : estimated required memory for 148759 words and 50 dimensions: 133887500 bytes\n",
      "2018-12-04 16:11:06,999 : INFO : resetting layer weights\n",
      "2018-12-04 16:11:08,211 : INFO : training model with 8 workers on 148759 vocabulary and 50 features, using sg=0 hs=0 sample=0.0001 negative=5 window=5\n",
      "2018-12-04 16:11:09,221 : INFO : EPOCH 1 - PROGRESS: at 7.68% examples, 493522 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:10,229 : INFO : EPOCH 1 - PROGRESS: at 16.50% examples, 528228 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:11,239 : INFO : EPOCH 1 - PROGRESS: at 25.58% examples, 544515 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:12,260 : INFO : EPOCH 1 - PROGRESS: at 35.31% examples, 559756 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:13,276 : INFO : EPOCH 1 - PROGRESS: at 42.85% examples, 543793 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:14,283 : INFO : EPOCH 1 - PROGRESS: at 50.15% examples, 530745 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:15,292 : INFO : EPOCH 1 - PROGRESS: at 58.46% examples, 527324 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:16,295 : INFO : EPOCH 1 - PROGRESS: at 68.05% examples, 535131 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:17,306 : INFO : EPOCH 1 - PROGRESS: at 77.21% examples, 539787 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:18,318 : INFO : EPOCH 1 - PROGRESS: at 86.88% examples, 541969 words/s, in_qsize 16, out_qsize 1\n",
      "2018-12-04 16:11:19,322 : INFO : EPOCH 1 - PROGRESS: at 95.79% examples, 544449 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:19,730 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:11:19,748 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:11:19,756 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:11:19,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:11:19,787 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:11:19,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:11:19,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:11:19,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:11:19,798 : INFO : EPOCH - 1 : training on 7723626 raw words (6357303 effective words) took 11.6s, 548857 effective words/s\n",
      "2018-12-04 16:11:20,820 : INFO : EPOCH 2 - PROGRESS: at 9.02% examples, 575906 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:21,841 : INFO : EPOCH 2 - PROGRESS: at 18.27% examples, 578038 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:22,841 : INFO : EPOCH 2 - PROGRESS: at 27.59% examples, 584906 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:23,858 : INFO : EPOCH 2 - PROGRESS: at 36.58% examples, 578611 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:24,909 : INFO : EPOCH 2 - PROGRESS: at 45.83% examples, 575662 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:25,934 : INFO : EPOCH 2 - PROGRESS: at 55.01% examples, 574397 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:26,978 : INFO : EPOCH 2 - PROGRESS: at 64.30% examples, 570002 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:27,982 : INFO : EPOCH 2 - PROGRESS: at 72.91% examples, 566413 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:28,986 : INFO : EPOCH 2 - PROGRESS: at 82.05% examples, 565860 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:29,991 : INFO : EPOCH 2 - PROGRESS: at 90.59% examples, 562546 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:30,906 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:11:30,924 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:11:30,927 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:11:30,957 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:11:30,961 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:11:30,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:11:30,966 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:11:30,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:11:30,971 : INFO : EPOCH - 2 : training on 7723626 raw words (6356879 effective words) took 11.2s, 569241 effective words/s\n",
      "2018-12-04 16:11:31,998 : INFO : EPOCH 3 - PROGRESS: at 8.44% examples, 533375 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:33,005 : INFO : EPOCH 3 - PROGRESS: at 16.75% examples, 532431 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:34,021 : INFO : EPOCH 3 - PROGRESS: at 25.92% examples, 548900 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:35,044 : INFO : EPOCH 3 - PROGRESS: at 33.19% examples, 524659 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:36,060 : INFO : EPOCH 3 - PROGRESS: at 41.85% examples, 528486 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:37,106 : INFO : EPOCH 3 - PROGRESS: at 50.79% examples, 532089 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:38,114 : INFO : EPOCH 3 - PROGRESS: at 61.29% examples, 546680 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:39,119 : INFO : EPOCH 3 - PROGRESS: at 70.44% examples, 548941 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:40,124 : INFO : EPOCH 3 - PROGRESS: at 80.08% examples, 555894 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:41,132 : INFO : EPOCH 3 - PROGRESS: at 90.61% examples, 564302 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:41,894 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:11:41,907 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:11:41,918 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:11:41,936 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:11:41,941 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:11:41,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:11:41,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:11:41,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:11:41,952 : INFO : EPOCH - 3 : training on 7723626 raw words (6356649 effective words) took 11.0s, 579150 effective words/s\n",
      "2018-12-04 16:11:42,963 : INFO : EPOCH 4 - PROGRESS: at 10.66% examples, 686927 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:44,001 : INFO : EPOCH 4 - PROGRESS: at 20.59% examples, 650809 words/s, in_qsize 14, out_qsize 1\n",
      "2018-12-04 16:11:45,025 : INFO : EPOCH 4 - PROGRESS: at 31.28% examples, 655560 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:46,035 : INFO : EPOCH 4 - PROGRESS: at 42.34% examples, 666686 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:47,053 : INFO : EPOCH 4 - PROGRESS: at 52.80% examples, 663765 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:48,061 : INFO : EPOCH 4 - PROGRESS: at 64.42% examples, 671083 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:49,067 : INFO : EPOCH 4 - PROGRESS: at 74.67% examples, 667280 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:50,068 : INFO : EPOCH 4 - PROGRESS: at 85.33% examples, 663605 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:51,070 : INFO : EPOCH 4 - PROGRESS: at 95.56% examples, 661546 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:51,439 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:11:51,458 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:11:51,466 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:11:51,479 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:11:51,488 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:11:51,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:11:51,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:11:51,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:11:51,499 : INFO : EPOCH - 4 : training on 7723626 raw words (6355556 effective words) took 9.5s, 666042 effective words/s\n",
      "2018-12-04 16:11:52,514 : INFO : EPOCH 5 - PROGRESS: at 10.29% examples, 659743 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:53,515 : INFO : EPOCH 5 - PROGRESS: at 20.48% examples, 657750 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:54,521 : INFO : EPOCH 5 - PROGRESS: at 30.38% examples, 647845 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:55,528 : INFO : EPOCH 5 - PROGRESS: at 40.50% examples, 645319 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:11:56,536 : INFO : EPOCH 5 - PROGRESS: at 50.52% examples, 644972 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:57,537 : INFO : EPOCH 5 - PROGRESS: at 61.02% examples, 644077 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:58,542 : INFO : EPOCH 5 - PROGRESS: at 71.67% examples, 646414 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:11:59,545 : INFO : EPOCH 5 - PROGRESS: at 82.72% examples, 651074 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:00,556 : INFO : EPOCH 5 - PROGRESS: at 93.70% examples, 651844 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:01,145 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:01,163 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:01,167 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:01,186 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:01,190 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:01,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:01,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:01,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:01,202 : INFO : EPOCH - 5 : training on 7723626 raw words (6357109 effective words) took 9.7s, 655423 effective words/s\n",
      "2018-12-04 16:12:02,217 : INFO : EPOCH 6 - PROGRESS: at 9.26% examples, 595117 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:03,226 : INFO : EPOCH 6 - PROGRESS: at 19.40% examples, 619027 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:04,233 : INFO : EPOCH 6 - PROGRESS: at 29.16% examples, 619174 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:05,247 : INFO : EPOCH 6 - PROGRESS: at 38.37% examples, 608671 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:06,305 : INFO : EPOCH 6 - PROGRESS: at 47.80% examples, 601852 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:07,344 : INFO : EPOCH 6 - PROGRESS: at 57.12% examples, 594937 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:08,355 : INFO : EPOCH 6 - PROGRESS: at 67.80% examples, 602591 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:09,364 : INFO : EPOCH 6 - PROGRESS: at 77.46% examples, 603663 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:10,367 : INFO : EPOCH 6 - PROGRESS: at 87.59% examples, 603120 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:11,408 : INFO : EPOCH 6 - PROGRESS: at 97.32% examples, 603075 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:11,613 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:11,629 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:11,637 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:11,658 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:11,662 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:11,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:11,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:11,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:11,675 : INFO : EPOCH - 6 : training on 7723626 raw words (6357571 effective words) took 10.5s, 607307 effective words/s\n",
      "2018-12-04 16:12:12,683 : INFO : EPOCH 7 - PROGRESS: at 9.92% examples, 640696 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:13,685 : INFO : EPOCH 7 - PROGRESS: at 20.12% examples, 647850 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:14,686 : INFO : EPOCH 7 - PROGRESS: at 30.61% examples, 655863 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:15,688 : INFO : EPOCH 7 - PROGRESS: at 40.13% examples, 642038 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:16,690 : INFO : EPOCH 7 - PROGRESS: at 49.04% examples, 628711 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:17,690 : INFO : EPOCH 7 - PROGRESS: at 56.09% examples, 596821 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:18,701 : INFO : EPOCH 7 - PROGRESS: at 65.33% examples, 591651 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:19,708 : INFO : EPOCH 7 - PROGRESS: at 74.68% examples, 591105 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:20,726 : INFO : EPOCH 7 - PROGRESS: at 84.40% examples, 589604 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:21,732 : INFO : EPOCH 7 - PROGRESS: at 96.00% examples, 603155 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:22,062 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:22,083 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:22,088 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:22,105 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:22,125 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:22,131 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:22,132 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:22,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:22,134 : INFO : EPOCH - 7 : training on 7723626 raw words (6356877 effective words) took 10.5s, 608058 effective words/s\n",
      "2018-12-04 16:12:23,149 : INFO : EPOCH 8 - PROGRESS: at 10.04% examples, 645139 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:24,154 : INFO : EPOCH 8 - PROGRESS: at 20.60% examples, 661518 words/s, in_qsize 16, out_qsize 1\n",
      "2018-12-04 16:12:25,157 : INFO : EPOCH 8 - PROGRESS: at 31.43% examples, 670013 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:26,166 : INFO : EPOCH 8 - PROGRESS: at 41.98% examples, 669500 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:27,176 : INFO : EPOCH 8 - PROGRESS: at 52.80% examples, 671945 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:28,178 : INFO : EPOCH 8 - PROGRESS: at 63.48% examples, 669175 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:29,179 : INFO : EPOCH 8 - PROGRESS: at 74.16% examples, 669538 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:30,185 : INFO : EPOCH 8 - PROGRESS: at 85.33% examples, 669126 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:31,189 : INFO : EPOCH 8 - PROGRESS: at 96.35% examples, 672618 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:31,510 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:31,518 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:31,520 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:31,553 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:31,560 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:31,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:31,569 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:31,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:31,571 : INFO : EPOCH - 8 : training on 7723626 raw words (6356360 effective words) took 9.4s, 674012 effective words/s\n",
      "2018-12-04 16:12:32,585 : INFO : EPOCH 9 - PROGRESS: at 9.92% examples, 636282 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:33,601 : INFO : EPOCH 9 - PROGRESS: at 20.61% examples, 657265 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:34,624 : INFO : EPOCH 9 - PROGRESS: at 31.17% examples, 657399 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:35,636 : INFO : EPOCH 9 - PROGRESS: at 41.98% examples, 663578 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:36,681 : INFO : EPOCH 9 - PROGRESS: at 52.93% examples, 664328 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:37,700 : INFO : EPOCH 9 - PROGRESS: at 64.56% examples, 670279 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:38,700 : INFO : EPOCH 9 - PROGRESS: at 74.95% examples, 668257 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:39,712 : INFO : EPOCH 9 - PROGRESS: at 86.53% examples, 669804 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:40,731 : INFO : EPOCH 9 - PROGRESS: at 97.78% examples, 675300 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:40,892 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:40,914 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:40,919 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:40,939 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:40,959 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:40,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:40,968 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:40,970 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:40,971 : INFO : EPOCH - 9 : training on 7723626 raw words (6356085 effective words) took 9.4s, 676573 effective words/s\n",
      "2018-12-04 16:12:41,998 : INFO : EPOCH 10 - PROGRESS: at 9.90% examples, 629236 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:43,001 : INFO : EPOCH 10 - PROGRESS: at 20.12% examples, 641568 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:44,012 : INFO : EPOCH 10 - PROGRESS: at 30.15% examples, 638689 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:45,042 : INFO : EPOCH 10 - PROGRESS: at 38.50% examples, 606785 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:12:46,047 : INFO : EPOCH 10 - PROGRESS: at 48.13% examples, 609932 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:47,061 : INFO : EPOCH 10 - PROGRESS: at 58.19% examples, 610613 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:48,072 : INFO : EPOCH 10 - PROGRESS: at 68.74% examples, 615052 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:49,079 : INFO : EPOCH 10 - PROGRESS: at 79.42% examples, 622523 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:50,084 : INFO : EPOCH 10 - PROGRESS: at 90.34% examples, 627545 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:12:50,876 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:12:50,893 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:12:50,900 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:12:50,915 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:12:50,923 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:12:50,927 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:12:50,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:12:50,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:12:50,933 : INFO : EPOCH - 10 : training on 7723626 raw words (6357273 effective words) took 10.0s, 638517 effective words/s\n",
      "2018-12-04 16:12:50,933 : INFO : training on a 77236260 raw words (63567662 effective words) took 102.7s, 618833 effective words/s\n",
      "2018-12-04 16:12:50,949 : INFO : saving Doc2Vec object under Doc2Vec_model/Doc2Vec_dm=True&cc=41418&vs=50&win=5&min=1&sample=0.0001&epochs=10, separately None\n",
      "2018-12-04 16:12:51,840 : INFO : saved Doc2Vec_model/Doc2Vec_dm=True&cc=41418&vs=50&win=5&min=1&sample=0.0001&epochs=10\n",
      "2018-12-04 16:14:06,842 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-12-04 16:14:06,934 : INFO : collecting all words and their counts\n",
      "2018-12-04 16:14:06,934 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-04 16:14:07,220 : INFO : PROGRESS: at example #10000, processed 1884311 words (6595444/s), 81597 word types, 11 tags\n",
      "2018-12-04 16:14:07,538 : INFO : PROGRESS: at example #20000, processed 3762527 words (5917540/s), 110172 word types, 11 tags\n",
      "2018-12-04 16:14:07,850 : INFO : PROGRESS: at example #30000, processed 5590210 words (5868573/s), 130122 word types, 11 tags\n",
      "2018-12-04 16:14:08,156 : INFO : PROGRESS: at example #40000, processed 7430810 words (6021930/s), 143472 word types, 11 tags\n",
      "2018-12-04 16:14:08,209 : INFO : collected 148759 word types and 11 unique tags from a corpus of 41418 examples and 7723626 words\n",
      "2018-12-04 16:14:08,210 : INFO : Loading a fresh vocabulary\n",
      "2018-12-04 16:14:08,955 : INFO : effective_min_count=1 retains 148759 unique words (100% of original 148759, drops 0)\n",
      "2018-12-04 16:14:08,956 : INFO : effective_min_count=1 leaves 7723626 word corpus (100% of original 7723626, drops 0)\n",
      "2018-12-04 16:14:09,300 : INFO : deleting the raw counts dictionary of 148759 items\n",
      "2018-12-04 16:14:09,304 : INFO : sample=0.0001 downsamples 715 most-common words\n",
      "2018-12-04 16:14:09,304 : INFO : downsampling leaves estimated 6315301 word corpus (81.8% of prior 7723626)\n",
      "2018-12-04 16:14:09,803 : INFO : estimated required memory for 148759 words and 50 dimensions: 133887500 bytes\n",
      "2018-12-04 16:14:09,803 : INFO : resetting layer weights\n",
      "2018-12-04 16:14:10,946 : INFO : training model with 8 workers on 148759 vocabulary and 50 features, using sg=0 hs=0 sample=0.0001 negative=5 window=15\n",
      "2018-12-04 16:14:11,952 : INFO : EPOCH 1 - PROGRESS: at 12.17% examples, 786414 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:12,959 : INFO : EPOCH 1 - PROGRESS: at 24.97% examples, 799433 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:13,966 : INFO : EPOCH 1 - PROGRESS: at 37.40% examples, 793579 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:14,975 : INFO : EPOCH 1 - PROGRESS: at 49.68% examples, 792486 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:15,978 : INFO : EPOCH 1 - PROGRESS: at 62.67% examples, 793919 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:16,987 : INFO : EPOCH 1 - PROGRESS: at 75.46% examples, 794060 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:17,989 : INFO : EPOCH 1 - PROGRESS: at 88.71% examples, 796379 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:18,815 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:14:18,822 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:14:18,832 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:14:18,841 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:14:18,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:14:18,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:14:18,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:14:18,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:14:18,852 : INFO : EPOCH - 1 : training on 7723626 raw words (6356582 effective words) took 7.9s, 804472 effective words/s\n",
      "2018-12-04 16:14:19,861 : INFO : EPOCH 2 - PROGRESS: at 10.53% examples, 679578 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:20,865 : INFO : EPOCH 2 - PROGRESS: at 19.88% examples, 638382 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:21,906 : INFO : EPOCH 2 - PROGRESS: at 30.27% examples, 638313 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:22,912 : INFO : EPOCH 2 - PROGRESS: at 41.48% examples, 656438 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:23,918 : INFO : EPOCH 2 - PROGRESS: at 51.90% examples, 657052 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:24,924 : INFO : EPOCH 2 - PROGRESS: at 62.43% examples, 655089 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:25,930 : INFO : EPOCH 2 - PROGRESS: at 73.16% examples, 657166 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:26,939 : INFO : EPOCH 2 - PROGRESS: at 84.73% examples, 661998 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:27,955 : INFO : EPOCH 2 - PROGRESS: at 95.56% examples, 662788 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:28,342 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:14:28,349 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:14:28,350 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:14:28,364 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:14:28,376 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:14:28,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:14:28,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:14:28,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:14:28,388 : INFO : EPOCH - 2 : training on 7723626 raw words (6357488 effective words) took 9.5s, 666946 effective words/s\n",
      "2018-12-04 16:14:29,403 : INFO : EPOCH 3 - PROGRESS: at 10.04% examples, 643632 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:30,421 : INFO : EPOCH 3 - PROGRESS: at 19.26% examples, 612643 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:31,422 : INFO : EPOCH 3 - PROGRESS: at 30.04% examples, 637575 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:32,434 : INFO : EPOCH 3 - PROGRESS: at 40.62% examples, 644848 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:33,448 : INFO : EPOCH 3 - PROGRESS: at 51.61% examples, 654934 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:34,472 : INFO : EPOCH 3 - PROGRESS: at 62.40% examples, 653878 words/s, in_qsize 16, out_qsize 1\n",
      "2018-12-04 16:14:35,508 : INFO : EPOCH 3 - PROGRESS: at 73.41% examples, 655568 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:36,511 : INFO : EPOCH 3 - PROGRESS: at 84.73% examples, 659026 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:37,513 : INFO : EPOCH 3 - PROGRESS: at 95.22% examples, 658515 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:37,993 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:14:38,014 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:14:38,021 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:14:38,027 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:14:38,045 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:14:38,051 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:14:38,055 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:14:38,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:14:38,057 : INFO : EPOCH - 3 : training on 7723626 raw words (6356842 effective words) took 9.7s, 657788 effective words/s\n",
      "2018-12-04 16:14:39,067 : INFO : EPOCH 4 - PROGRESS: at 8.31% examples, 533722 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:40,081 : INFO : EPOCH 4 - PROGRESS: at 17.23% examples, 551317 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:41,094 : INFO : EPOCH 4 - PROGRESS: at 26.96% examples, 572710 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:42,098 : INFO : EPOCH 4 - PROGRESS: at 35.99% examples, 571101 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:43,116 : INFO : EPOCH 4 - PROGRESS: at 45.19% examples, 573475 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:44,146 : INFO : EPOCH 4 - PROGRESS: at 55.01% examples, 578872 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:45,152 : INFO : EPOCH 4 - PROGRESS: at 65.84% examples, 590450 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:46,156 : INFO : EPOCH 4 - PROGRESS: at 76.62% examples, 601266 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:47,161 : INFO : EPOCH 4 - PROGRESS: at 87.35% examples, 605381 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:48,170 : INFO : EPOCH 4 - PROGRESS: at 97.45% examples, 609464 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:48,366 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:14:48,386 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:14:48,392 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:14:48,411 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:14:48,414 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:14:48,417 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:14:48,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:14:48,437 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:14:48,439 : INFO : EPOCH - 4 : training on 7723626 raw words (6357627 effective words) took 10.4s, 612612 effective words/s\n",
      "2018-12-04 16:14:49,460 : INFO : EPOCH 5 - PROGRESS: at 9.39% examples, 601035 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:50,477 : INFO : EPOCH 5 - PROGRESS: at 19.89% examples, 631713 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:51,492 : INFO : EPOCH 5 - PROGRESS: at 30.15% examples, 636579 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:52,503 : INFO : EPOCH 5 - PROGRESS: at 40.51% examples, 640159 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:53,505 : INFO : EPOCH 5 - PROGRESS: at 51.09% examples, 648030 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:54,515 : INFO : EPOCH 5 - PROGRESS: at 62.16% examples, 652365 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:55,526 : INFO : EPOCH 5 - PROGRESS: at 72.91% examples, 654274 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:56,534 : INFO : EPOCH 5 - PROGRESS: at 81.51% examples, 638440 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:14:57,534 : INFO : EPOCH 5 - PROGRESS: at 92.13% examples, 639846 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:14:58,246 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:14:58,260 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:14:58,270 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:14:58,279 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:14:58,295 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:14:58,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:14:58,300 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:14:58,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:14:58,302 : INFO : EPOCH - 5 : training on 7723626 raw words (6357079 effective words) took 9.9s, 644970 effective words/s\n",
      "2018-12-04 16:14:59,310 : INFO : EPOCH 6 - PROGRESS: at 9.39% examples, 607031 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:00,319 : INFO : EPOCH 6 - PROGRESS: at 17.48% examples, 560912 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:01,342 : INFO : EPOCH 6 - PROGRESS: at 26.05% examples, 553229 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:02,345 : INFO : EPOCH 6 - PROGRESS: at 34.39% examples, 546351 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:03,366 : INFO : EPOCH 6 - PROGRESS: at 42.72% examples, 542232 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:04,385 : INFO : EPOCH 6 - PROGRESS: at 51.76% examples, 545864 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:05,387 : INFO : EPOCH 6 - PROGRESS: at 61.16% examples, 549908 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:06,399 : INFO : EPOCH 6 - PROGRESS: at 70.03% examples, 549273 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:07,417 : INFO : EPOCH 6 - PROGRESS: at 78.62% examples, 548428 words/s, in_qsize 14, out_qsize 1\n",
      "2018-12-04 16:15:08,417 : INFO : EPOCH 6 - PROGRESS: at 87.82% examples, 547948 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:09,428 : INFO : EPOCH 6 - PROGRESS: at 97.78% examples, 555911 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:09,638 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:15:09,649 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:15:09,657 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:15:09,677 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:15:09,683 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:15:09,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:15:09,707 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:15:09,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:15:09,713 : INFO : EPOCH - 6 : training on 7723626 raw words (6356855 effective words) took 11.4s, 557236 effective words/s\n",
      "2018-12-04 16:15:10,730 : INFO : EPOCH 7 - PROGRESS: at 8.76% examples, 564331 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:11,735 : INFO : EPOCH 7 - PROGRESS: at 17.88% examples, 572766 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:12,747 : INFO : EPOCH 7 - PROGRESS: at 28.25% examples, 600513 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:13,750 : INFO : EPOCH 7 - PROGRESS: at 39.76% examples, 632589 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:14,788 : INFO : EPOCH 7 - PROGRESS: at 51.87% examples, 656496 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:15,790 : INFO : EPOCH 7 - PROGRESS: at 65.20% examples, 683115 words/s, in_qsize 14, out_qsize 1\n",
      "2018-12-04 16:15:16,803 : INFO : EPOCH 7 - PROGRESS: at 77.87% examples, 698629 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:17,803 : INFO : EPOCH 7 - PROGRESS: at 89.04% examples, 696566 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:18,742 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:15:18,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:15:18,752 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:15:18,764 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:15:18,775 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:15:18,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:15:18,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:15:18,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:15:18,782 : INFO : EPOCH - 7 : training on 7723626 raw words (6357186 effective words) took 9.1s, 701580 effective words/s\n",
      "2018-12-04 16:15:19,789 : INFO : EPOCH 8 - PROGRESS: at 10.29% examples, 666421 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:20,791 : INFO : EPOCH 8 - PROGRESS: at 21.21% examples, 685090 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:21,796 : INFO : EPOCH 8 - PROGRESS: at 32.19% examples, 688044 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:22,798 : INFO : EPOCH 8 - PROGRESS: at 44.77% examples, 716699 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:23,825 : INFO : EPOCH 8 - PROGRESS: at 56.09% examples, 712076 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:24,846 : INFO : EPOCH 8 - PROGRESS: at 67.13% examples, 704467 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:25,865 : INFO : EPOCH 8 - PROGRESS: at 77.87% examples, 699183 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:26,867 : INFO : EPOCH 8 - PROGRESS: at 88.94% examples, 695803 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:27,861 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:15:27,876 : INFO : EPOCH 8 - PROGRESS: at 99.32% examples, 693800 words/s, in_qsize 6, out_qsize 1\n",
      "2018-12-04 16:15:27,877 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:15:27,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:15:27,903 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:15:27,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:15:27,907 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:15:27,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:15:27,914 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:15:27,915 : INFO : EPOCH - 8 : training on 7723626 raw words (6356614 effective words) took 9.1s, 696450 effective words/s\n",
      "2018-12-04 16:15:28,927 : INFO : EPOCH 9 - PROGRESS: at 9.92% examples, 637836 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:29,942 : INFO : EPOCH 9 - PROGRESS: at 20.48% examples, 654470 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:30,946 : INFO : EPOCH 9 - PROGRESS: at 32.19% examples, 683726 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:31,950 : INFO : EPOCH 9 - PROGRESS: at 44.17% examples, 703055 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:32,952 : INFO : EPOCH 9 - PROGRESS: at 54.99% examples, 699788 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:33,954 : INFO : EPOCH 9 - PROGRESS: at 66.38% examples, 699207 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:34,955 : INFO : EPOCH 9 - PROGRESS: at 77.35% examples, 698736 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:35,975 : INFO : EPOCH 9 - PROGRESS: at 89.89% examples, 705832 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:36,718 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:15:36,721 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:15:36,734 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:15:36,746 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:15:36,760 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:15:36,761 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:15:36,762 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:15:36,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:15:36,763 : INFO : EPOCH - 9 : training on 7723626 raw words (6357809 effective words) took 8.8s, 718963 effective words/s\n",
      "2018-12-04 16:15:37,780 : INFO : EPOCH 10 - PROGRESS: at 11.27% examples, 725210 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:38,782 : INFO : EPOCH 10 - PROGRESS: at 23.04% examples, 738629 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:39,797 : INFO : EPOCH 10 - PROGRESS: at 35.46% examples, 750989 words/s, in_qsize 15, out_qsize 1\n",
      "2018-12-04 16:15:40,808 : INFO : EPOCH 10 - PROGRESS: at 47.81% examples, 760322 words/s, in_qsize 16, out_qsize 0\n",
      "2018-12-04 16:15:41,813 : INFO : EPOCH 10 - PROGRESS: at 60.77% examples, 767706 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:42,817 : INFO : EPOCH 10 - PROGRESS: at 73.28% examples, 770405 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:43,817 : INFO : EPOCH 10 - PROGRESS: at 86.76% examples, 776022 words/s, in_qsize 15, out_qsize 0\n",
      "2018-12-04 16:15:44,832 : INFO : EPOCH 10 - PROGRESS: at 99.19% examples, 781324 words/s, in_qsize 7, out_qsize 1\n",
      "2018-12-04 16:15:44,833 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-04 16:15:44,839 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-04 16:15:44,841 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-04 16:15:44,850 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-04 16:15:44,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-04 16:15:44,863 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-04 16:15:44,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-04 16:15:44,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-04 16:15:44,869 : INFO : EPOCH - 10 : training on 7723626 raw words (6357589 effective words) took 8.1s, 785113 effective words/s\n",
      "2018-12-04 16:15:44,870 : INFO : training on a 77236260 raw words (63571671 effective words) took 93.9s, 676851 effective words/s\n",
      "2018-12-04 16:15:44,879 : INFO : saving Doc2Vec object under Doc2Vec_model/Doc2Vec_dm=True&cc=41418&vs=50&win=15&min=1&sample=0.0001&epochs=10, separately None\n",
      "2018-12-04 16:15:45,732 : INFO : saved Doc2Vec_model/Doc2Vec_dm=True&cc=41418&vs=50&win=15&min=1&sample=0.0001&epochs=10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_dict = {\n",
    "                'corpus_count' : [],\n",
    "               'min_count' : [],\n",
    "               'vector_size' : [],\n",
    "               'window' : [],\n",
    "               'n_epochs' : [],\n",
    "               'accuracy' : [],\n",
    "               'sample' : [],\n",
    "               'dm' : [],\n",
    "              }\n",
    "\n",
    "testing_section_ls = ['경제','기업','사회','국제','부동산','증권','정치','IT과학','문화']\n",
    "\n",
    "# 하이퍼 파라미터 튜닝 작업 수행\n",
    "\n",
    "for dm in [1]:\n",
    "    for doc2vec_size in ['']:\n",
    "        if doc2vec_size == '':\n",
    "            x_split, y_split = token_ls, label_ls\n",
    "\n",
    "        for sample in [1e-04, 1e-05, 1e-06]:\n",
    "            for min_count in [1, 5, 15, 50]:\n",
    "                for vector_size in [100,300]:\n",
    "                    for window in [5,15]:\n",
    "                        for n_epochs in [10]:\n",
    "\n",
    "                            # Doc2Vec 모델 생성\n",
    "                            nlp.make_Doc2Vec_model(dm = dm,\n",
    "                                                   min_count = min_count,\n",
    "                                                   sample = sample,\n",
    "                                                   vector_size = vector_size,\n",
    "                                                   window = window,\n",
    "                                                   dm_mean = 0,\n",
    "                                                   dm_concat = 0)\n",
    "\n",
    "                            nlp.build_and_train_Doc2Vec_model(x_split,\n",
    "                                                              y_split,\n",
    "                                                              n_epochs = n_epochs)\n",
    "\n",
    "\n",
    "                            model_name = 'Doc2Vec_dm=%s&cc=%s&vs=%s&win=%s&min=%s&sample=%s&epochs=%s'%(\\\n",
    "                                                                                                                 nlp.Doc2Vec_model.dm,\n",
    "                                                                                                                   nlp.Doc2Vec_model.corpus_count,\n",
    "                                                                                                                   nlp.Doc2Vec_model.vector_size,\n",
    "                                                                                                                   nlp.Doc2Vec_model.window,\n",
    "                                                                                                                   nlp.Doc2Vec_model.min_count,\n",
    "                                                                                                                   nlp.Doc2Vec_model.sample,\n",
    "                                                                                                                   nlp.Doc2Vec_model.epochs)\n",
    "                            # Doc2Vec 모델 저장\n",
    "                            nlp.Doc2Vec_model.save('Doc2Vec_model/'+model_name)\n",
    "\n",
    "                            '''\n",
    "                            X =nlp.infer_vectors_with_Doc2Vec(train_token_ls_split)\n",
    "\n",
    "                            from sklearn.decomposition import PCA\n",
    "\n",
    "                            pca = PCA(n_components=2)\n",
    "                            X_pca = pca.fit_transform(X)\n",
    "                            scatter_df = pd.DataFrame(X_pca,\n",
    "                                                      index = train_tag_ls_split,\n",
    "                                                      columns = ['x','y'])\n",
    "\n",
    "                            plt.figure(figsize = (15, 15))\n",
    "\n",
    "                            for section in testing_section_ls:\n",
    "                                temp_df = scatter_df[scatter_df.index == section]\n",
    "                                plt.scatter(temp_df['x'].values, temp_df['y'].values, label = section, c = np.random.rand(3,))\n",
    "\n",
    "                            plt.legend(loc = 'best')\n",
    "                            #plt.savefig('Doc2Vec_model/images/'+model_name)\n",
    "                            #plt.imshow()\n",
    "\n",
    "                            '''\n",
    "                            \n",
    "                            # clf를 각 레이블별 1000개씩 학습, \n",
    "                            X_train = nlp.infer_vectors_with_Doc2Vec(train_token_ls_split)\n",
    "                            y_train = train_tag_ls_split\n",
    "\n",
    "                            X_test = nlp.infer_vectors_with_Doc2Vec(test_token_ls_split)\n",
    "                            y_test = test_tag_ls_split\n",
    "\n",
    "\n",
    "                            clf = LogisticRegression(solver = 'sag',\n",
    "                                                     multi_class = 'multinomial')\n",
    "\n",
    "\n",
    "                            clf.fit(X_train, y_train)\n",
    "                            y_pred = clf.predict(X_test)\n",
    "                            \n",
    "                            result_dict['dm'].append(nlp.Doc2Vec_model.dm)\n",
    "                            result_dict['corpus_count'].append(nlp.Doc2Vec_model.corpus_count)\n",
    "                            result_dict['min_count'].append(nlp.Doc2Vec_model.min_count)\n",
    "                            result_dict['vector_size'].append(nlp.Doc2Vec_model.vector_size)\n",
    "                            result_dict['window'].append(nlp.Doc2Vec_model.window)\n",
    "                            result_dict['n_epochs'].append(nlp.Doc2Vec_model.epochs)\n",
    "                            result_dict['sample'].append(nlp.Doc2Vec_model.sample)\n",
    "                            result_dict['accuracy'].append(accuracy_score(y_pred, y_test))\n",
    "\n",
    "                            print(accuracy_score(y_pred, y_test))\n",
    "\n",
    "\n",
    "            pd.DataFrame(result_dict).to_csv('Parameter_tuning_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Doc2Vec_model.docvecs.vectors_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fininsight_python_3.5",
   "language": "python",
   "name": "fininsight_python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
