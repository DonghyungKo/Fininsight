{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unset PYTHONPATH first\n",
    "from ko_text import *\n",
    "from ko_crawler import *\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = NLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Data/morphs/train_morphs_final.csv', encoding = 'utf-8')\n",
    "test_df = pd.read_csv('Data/morphs/test_morphs_final.csv', encoding = 'utf-8')\n",
    "\n",
    "# 용량을 줄이기 위해 '단어 단어' 꼴로 묶어둔 token을 ['단어', '단어'] 꼴로 풀기\n",
    "train_df['Token'] = [token.split() for token in train_df['Token']]\n",
    "test_df['Token'] = [token.split() for token in test_df['Token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82963, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'IT과학': 9836,\n",
       "         '경제': 8050,\n",
       "         '국제': 9677,\n",
       "         '기업': 9604,\n",
       "         '문화': 9313,\n",
       "         '부동산': 9714,\n",
       "         '사회': 9325,\n",
       "         '정치': 8875,\n",
       "         '증권': 8569})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df['Section'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가장 문제가 많은 기업, 증권 기사를 제거하면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['Section'].isin(['증권','기업'])]\n",
    "test_df = test_df[~test_df['Section'].isin(['증권','기업'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'IT과학': 9869,\n",
       "         '경제': 8400,\n",
       "         '국제': 9730,\n",
       "         '문화': 9392,\n",
       "         '부동산': 9771,\n",
       "         '사회': 9483,\n",
       "         '정치': 8966})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df['Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'IT과학': 2483,\n",
       "         '경제': 1943,\n",
       "         '국제': 2440,\n",
       "         '문화': 2334,\n",
       "         '부동산': 2466,\n",
       "         '사회': 2369,\n",
       "         '정치': 2317})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_df['Section'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Doc2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Doc2Vec 모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7f82a01d72e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 성능이 좋았던 모델들 호출\n",
    "nlp.load_Doc2Vec_model('Doc2Vec_model/Doc2Vec_dm=True&cc=82963&vs=300&win=10&neg=5&min=10&sample=1e-05&epochs=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Doc2Vec train** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nlp.train_Doc2Vec_model(train_df['Token'],\\n                        train_df['Section'],\\n                        n_epochs = 10)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''nlp.train_Doc2Vec_model(train_df['Token'],\n",
    "                        train_df['Section'],\n",
    "                        n_epochs = 10)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Doc2Vec 학습결과 확인**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **88000개 문서로 build하고 87000개 문서로 train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('지능', 0.9414902925491333),\n",
       " ('빅데이터', 0.7357947826385498),\n",
       " ('음성인식', 0.7320722341537476),\n",
       " ('사물인터넷', 0.7252418994903564),\n",
       " ('접목', 0.6725608110427856),\n",
       " ('러닝', 0.6664267182350159),\n",
       " ('머신', 0.6464930772781372),\n",
       " ('기계학습', 0.64275062084198),\n",
       " ('로봇', 0.6422725915908813),\n",
       " ('자연어', 0.6374872326850891)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Doc2Vec_model.most_similar('인공')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'IT과학': 8000,\n",
       "         '경제': 8000,\n",
       "         '국제': 8000,\n",
       "         '기업': 8000,\n",
       "         '문화': 8000,\n",
       "         '부동산': 8000,\n",
       "         '사회': 8000,\n",
       "         '정치': 8000,\n",
       "         '증권': 8000})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "# 한 label마다 학습할 단어의 수\n",
    "train_size_for_each_label = 8000\n",
    "test_size_for_each_label = 1000\n",
    "###################################\n",
    "\n",
    "\n",
    "# 분류기의 성능을 테스트하기 위해 선정된 section list\n",
    "testing_section_ls = np.unique(train_df['Section'])\n",
    "#testing_section_ls = ['사회','IT과학']\n",
    "\n",
    "# 전체를 모두 학습하면 시간이 오래걸림.\n",
    "# 분류기별 성능 비교를 위해, 부분만 학습하기 위한 전처리 작업\n",
    "train_df2 = train_df[train_df['Section'].isin(testing_section_ls)]\n",
    "train_df2.index = np.arange(0,len(train_df2))\n",
    "\n",
    "test_df2 = test_df[test_df['Section'].isin(testing_section_ls)]\n",
    "test_df2.index = np.arange(0,len(test_df2))\n",
    "\n",
    "n_class = len(test_df2['Section'].unique())\n",
    "\n",
    "\n",
    "# Doc2Vec으로 vector를 추정하기 위한 split 과정\n",
    "train_batch_size = n_class * train_size_for_each_label\n",
    "test_batch_size = n_class * test_size_for_each_label\n",
    "\n",
    "X_train, y_train = nlp.extract_a_equally_splited_batch(train_df2['Token'], train_df2['Section'], train_batch_size)\n",
    "X_test, y_test =  nlp.extract_a_equally_splited_batch(test_df2['Token'],test_df2['Section'], test_batch_size)\n",
    "\n",
    "#print(1)\n",
    "\n",
    "X_train = nlp.infer_vectors_with_Doc2Vec(X_train)\n",
    "y_train = y_train\n",
    "\n",
    "X_test = nlp.infer_vectors_with_Doc2Vec(X_test)\n",
    "y_test = y_test\n",
    "\n",
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'IT과학': 1000,\n",
       "         '경제': 1000,\n",
       "         '국제': 1000,\n",
       "         '기업': 1000,\n",
       "         '문화': 1000,\n",
       "         '부동산': 1000,\n",
       "         '사회': 1000,\n",
       "         '정치': 1000,\n",
       "         '증권': 1000})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.6986666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver = 'newton-cg',\n",
    "                         multi_class = 'multinomial')\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy : ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT과학</th>\n",
       "      <th>경제</th>\n",
       "      <th>국제</th>\n",
       "      <th>기업</th>\n",
       "      <th>문화</th>\n",
       "      <th>부동산</th>\n",
       "      <th>사회</th>\n",
       "      <th>정치</th>\n",
       "      <th>증권</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IT과학</th>\n",
       "      <td>581</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>210</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경제</th>\n",
       "      <td>59</td>\n",
       "      <td>493</td>\n",
       "      <td>50</td>\n",
       "      <td>114</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>국제</th>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>759</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기업</th>\n",
       "      <td>191</td>\n",
       "      <td>80</td>\n",
       "      <td>21</td>\n",
       "      <td>497</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문화</th>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>818</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부동산</th>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>844</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사회</th>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>715</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정치</th>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>760</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>증권</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IT과학   경제   국제   기업   문화  부동산   사회   정치   증권\n",
       "IT과학   581   38   28  210   29    9   48    7   50\n",
       "경제      59  493   50  114   10   35   47   26  166\n",
       "국제      27   64  759   28   25    6   24   40   27\n",
       "기업     191   80   21  497   30   15   62   19   85\n",
       "문화      23   11   15   13  818   14   73   28    5\n",
       "부동산     15   38    2   16   11  844   46   19    9\n",
       "사회      44   35   18   46   36   45  715   50   11\n",
       "정치       5   47   55   14   18    8   87  760    6\n",
       "증권      50   50    4   59    3   10    3    0  821"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(confusion_matrix(y_test, y_pred) ,\n",
    "                         index = sorted(train_df['Section'].unique()),\n",
    "                         columns = sorted(train_df['Section'].unique()))\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경제,기업 기사를 제일 못맞춘다. 정확도가 50%수준..\n",
    "\n",
    "### 문화 기사와 부동산, 증권 기사는 잘 맞춘다. \n",
    "\n",
    "### **증권 기사를 잘 맞추는 이유는 대부분 기사를 증권 기사라고 분류하기 때문**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 너무 많은 수의 기사를 [증권,사회] 기사라고 분류한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IT과학     995\n",
       "경제       856\n",
       "국제       952\n",
       "기업       997\n",
       "문화       980\n",
       "부동산      986\n",
       "사회      1105\n",
       "정치       949\n",
       "증권      1180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 왜 그럴까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 카테고리 별, 토큰 길이의 평균은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Section</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IT과학</th>\n",
       "      <td>9836.0</td>\n",
       "      <td>228.367222</td>\n",
       "      <td>150.858785</td>\n",
       "      <td>51.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>경제</th>\n",
       "      <td>8050.0</td>\n",
       "      <td>215.267702</td>\n",
       "      <td>144.405833</td>\n",
       "      <td>51.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>국제</th>\n",
       "      <td>9677.0</td>\n",
       "      <td>244.187765</td>\n",
       "      <td>131.619560</td>\n",
       "      <td>51.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>기업</th>\n",
       "      <td>9604.0</td>\n",
       "      <td>204.217618</td>\n",
       "      <td>137.728449</td>\n",
       "      <td>51.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문화</th>\n",
       "      <td>9313.0</td>\n",
       "      <td>248.453452</td>\n",
       "      <td>258.583833</td>\n",
       "      <td>51.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>4327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부동산</th>\n",
       "      <td>9714.0</td>\n",
       "      <td>224.478691</td>\n",
       "      <td>136.277920</td>\n",
       "      <td>51.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사회</th>\n",
       "      <td>9325.0</td>\n",
       "      <td>187.522681</td>\n",
       "      <td>121.342611</td>\n",
       "      <td>51.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>정치</th>\n",
       "      <td>8875.0</td>\n",
       "      <td>240.445746</td>\n",
       "      <td>147.590659</td>\n",
       "      <td>51.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>1776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>증권</th>\n",
       "      <td>8569.0</td>\n",
       "      <td>188.156261</td>\n",
       "      <td>103.081897</td>\n",
       "      <td>51.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1379.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count        mean         std   min    25%    50%    75%     max\n",
       "Section                                                                   \n",
       "IT과학     9836.0  228.367222  150.858785  51.0  133.0  191.0  279.0  2606.0\n",
       "경제       8050.0  215.267702  144.405833  51.0  114.0  174.0  279.0  2129.0\n",
       "국제       9677.0  244.187765  131.619560  51.0  154.0  219.0  300.0  1342.0\n",
       "기업       9604.0  204.217618  137.728449  51.0  119.0  171.0  250.0  2416.0\n",
       "문화       9313.0  248.453452  258.583833  51.0  112.0  176.0  314.0  4327.0\n",
       "부동산      9714.0  224.478691  136.277920  51.0  130.0  188.0  277.0  1302.0\n",
       "사회       9325.0  187.522681  121.342611  51.0  107.0  156.0  232.0  2020.0\n",
       "정치       8875.0  240.445746  147.590659  51.0  134.0  203.0  313.0  1776.0\n",
       "증권       8569.0  188.156261  103.081897  51.0  109.0  178.0  251.0  1379.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Section')['Num of Tokens'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 길이가 짧은 기사들은 하나로 몰아서 분류해버리는 경향이 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "section_ls = train_df['Section'].unique()\n",
    "\n",
    "store_dict = OrderedDict(\\\n",
    "                         {'Token의 수 n개 이상' : [],\n",
    "                          'Token의 수 n개 이하' : []})\n",
    "\n",
    "for section in section_ls:\n",
    "    store_dict[section] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token의 수 50이상 100 이하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 길이가 짧으면 증권, 사회 기사는 매우 잘 분류하지만, 정치, IT과학, 국제 기사는 잘 분류하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 카테고리의 분류 정확도는 46.00% \n",
      "기업 카테고리의 분류 정확도는 36.00% \n",
      "사회 카테고리의 분류 정확도는 75.00% \n",
      "국제 카테고리의 분류 정확도는 50.00% \n",
      "부동산 카테고리의 분류 정확도는 75.00% \n",
      "증권 카테고리의 분류 정확도는 92.00% \n",
      "정치 카테고리의 분류 정확도는 60.00% \n",
      "IT과학 카테고리의 분류 정확도는 31.00% \n",
      "문화 카테고리의 분류 정확도는 71.00% \n"
     ]
    }
   ],
   "source": [
    "lower_limit = 50\n",
    "upper_limit = 100\n",
    "\n",
    "temp_df = test_df[test_df['Num of Tokens'] > lower_limit]\n",
    "temp_df = test_df[test_df['Num of Tokens'] < upper_limit]\n",
    "\n",
    "store_dict['Token의 수 n개 이상'].append(lower_limit)\n",
    "store_dict['Token의 수 n개 이하'].append(upper_limit)\n",
    "\n",
    "for section in section_ls:\n",
    "    temp_section_df = temp_df[temp_df['Section'] == section]\n",
    "\n",
    "    temp_token_ls = temp_section_df['Token'].tolist()[:100] #100개만\n",
    "    temp_tag_ls = temp_section_df['Section'].tolist()[:100]\n",
    "\n",
    "    temp_pred = clf.predict(nlp.infer_vectors_with_Doc2Vec(temp_token_ls))\n",
    "    \n",
    "    store_dict[section].append('%s %s'%(round(accuracy_score(temp_tag_ls, temp_pred) * 100, 2), '%'))\n",
    "    print('%s 카테고리의 분류 정확도는 %.2f%% '%(section, accuracy_score(temp_tag_ls, temp_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token의 수 100개 이상, 300개 이하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 길이가 길어지면 경제, 사회 기사의 정확도는 떨어지지만, 반대로 부동산, 정치, IT과학 기사의 정확도가 급상승..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 카테고리의 분류 정확도는 43.00% \n",
      "기업 카테고리의 분류 정확도는 53.00% \n",
      "사회 카테고리의 분류 정확도는 76.00% \n",
      "국제 카테고리의 분류 정확도는 80.00% \n",
      "부동산 카테고리의 분류 정확도는 84.00% \n",
      "증권 카테고리의 분류 정확도는 80.00% \n",
      "정치 카테고리의 분류 정확도는 70.00% \n",
      "IT과학 카테고리의 분류 정확도는 63.00% \n",
      "문화 카테고리의 분류 정확도는 81.00% \n"
     ]
    }
   ],
   "source": [
    "lower_limit = 100\n",
    "upper_limit = 300\n",
    "\n",
    "temp_df = test_df[test_df['Num of Tokens'] > lower_limit]\n",
    "temp_df = test_df[test_df['Num of Tokens'] < upper_limit]\n",
    "\n",
    "store_dict['Token의 수 n개 이상'].append(lower_limit)\n",
    "store_dict['Token의 수 n개 이하'].append(upper_limit)\n",
    "\n",
    "for section in section_ls:\n",
    "    temp_section_df = temp_df[temp_df['Section'] == section]\n",
    "\n",
    "    temp_token_ls = temp_section_df['Token'].tolist()[:100] #100개만\n",
    "    temp_tag_ls = temp_section_df['Section'].tolist()[:100]\n",
    "\n",
    "    temp_pred = clf.predict(nlp.infer_vectors_with_Doc2Vec(temp_token_ls))\n",
    "    \n",
    "    store_dict[section].append('%s %s'%(round(accuracy_score(temp_tag_ls, temp_pred) * 100, 2), '%'))\n",
    "    print('%s 카테고리의 분류 정확도는 %.2f%% '%(section, accuracy_score(temp_tag_ls, temp_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token의 수 300개 이상, 500 이하"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 카테고리의 분류 정확도는 42.00% \n",
      "기업 카테고리의 분류 정확도는 57.00% \n",
      "사회 카테고리의 분류 정확도는 73.00% \n",
      "국제 카테고리의 분류 정확도는 77.00% \n",
      "부동산 카테고리의 분류 정확도는 86.00% \n",
      "증권 카테고리의 분류 정확도는 82.00% \n",
      "정치 카테고리의 분류 정확도는 70.00% \n",
      "IT과학 카테고리의 분류 정확도는 65.00% \n",
      "문화 카테고리의 분류 정확도는 83.00% \n"
     ]
    }
   ],
   "source": [
    "lower_limit = 300\n",
    "upper_limit = 500\n",
    "\n",
    "temp_df = test_df[test_df['Num of Tokens'] > lower_limit]\n",
    "temp_df = test_df[test_df['Num of Tokens'] < upper_limit]\n",
    "\n",
    "store_dict['Token의 수 n개 이상'].append(lower_limit)\n",
    "store_dict['Token의 수 n개 이하'].append(upper_limit)\n",
    "\n",
    "for section in section_ls:\n",
    "    temp_section_df = temp_df[temp_df['Section'] == section]\n",
    "\n",
    "    temp_token_ls = temp_section_df['Token'].tolist()[:100] #100개만\n",
    "    temp_tag_ls = temp_section_df['Section'].tolist()[:100]\n",
    "\n",
    "    temp_pred = clf.predict(nlp.infer_vectors_with_Doc2Vec(temp_token_ls))\n",
    "    \n",
    "    store_dict[section].append('%s %s'%(round(accuracy_score(temp_tag_ls, temp_pred) * 100, 2), '%'))\n",
    "    print('%s 카테고리의 분류 정확도는 %.2f%% '%(section, accuracy_score(temp_tag_ls, temp_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## token의 수 500개 초과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 카테고리의 분류 정확도는 44.00% \n",
      "기업 카테고리의 분류 정확도는 54.00% \n",
      "사회 카테고리의 분류 정확도는 75.00% \n",
      "국제 카테고리의 분류 정확도는 70.00% \n",
      "부동산 카테고리의 분류 정확도는 87.00% \n",
      "증권 카테고리의 분류 정확도는 81.00% \n",
      "정치 카테고리의 분류 정확도는 68.00% \n",
      "IT과학 카테고리의 분류 정확도는 62.00% \n",
      "문화 카테고리의 분류 정확도는 82.00% \n"
     ]
    }
   ],
   "source": [
    "lower_limit = 500\n",
    "upper_limit = 10000\n",
    "\n",
    "temp_df = test_df[test_df['Num of Tokens'] > lower_limit]\n",
    "temp_df = test_df[test_df['Num of Tokens'] < upper_limit]\n",
    "\n",
    "store_dict['Token의 수 n개 이상'].append(lower_limit)\n",
    "store_dict['Token의 수 n개 이하'].append(upper_limit)\n",
    "\n",
    "for section in section_ls:\n",
    "    temp_section_df = temp_df[temp_df['Section'] == section]\n",
    "\n",
    "    temp_token_ls = temp_section_df['Token'].tolist()[:100] #100개만\n",
    "    temp_tag_ls = temp_section_df['Section'].tolist()[:100]\n",
    "\n",
    "    temp_pred = clf.predict(nlp.infer_vectors_with_Doc2Vec(temp_token_ls))\n",
    "    \n",
    "    store_dict[section].append('%s %s'%(round(accuracy_score(temp_tag_ls, temp_pred) * 100, 2), '%'))\n",
    "    print('%s 카테고리의 분류 정확도는 %.2f%% '%(section, accuracy_score(temp_tag_ls, temp_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token의 수 n개 이상</th>\n",
       "      <th>Token의 수 n개 이하</th>\n",
       "      <th>경제</th>\n",
       "      <th>기업</th>\n",
       "      <th>사회</th>\n",
       "      <th>국제</th>\n",
       "      <th>부동산</th>\n",
       "      <th>증권</th>\n",
       "      <th>정치</th>\n",
       "      <th>IT과학</th>\n",
       "      <th>문화</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>46.0 %</td>\n",
       "      <td>36.0 %</td>\n",
       "      <td>75.0 %</td>\n",
       "      <td>50.0 %</td>\n",
       "      <td>75.0 %</td>\n",
       "      <td>92.0 %</td>\n",
       "      <td>60.0 %</td>\n",
       "      <td>31.0 %</td>\n",
       "      <td>71.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>43.0 %</td>\n",
       "      <td>53.0 %</td>\n",
       "      <td>76.0 %</td>\n",
       "      <td>80.0 %</td>\n",
       "      <td>84.0 %</td>\n",
       "      <td>80.0 %</td>\n",
       "      <td>70.0 %</td>\n",
       "      <td>63.0 %</td>\n",
       "      <td>81.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>42.0 %</td>\n",
       "      <td>57.0 %</td>\n",
       "      <td>73.0 %</td>\n",
       "      <td>77.0 %</td>\n",
       "      <td>86.0 %</td>\n",
       "      <td>82.0 %</td>\n",
       "      <td>70.0 %</td>\n",
       "      <td>65.0 %</td>\n",
       "      <td>83.0 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>10000</td>\n",
       "      <td>44.0 %</td>\n",
       "      <td>54.0 %</td>\n",
       "      <td>75.0 %</td>\n",
       "      <td>70.0 %</td>\n",
       "      <td>87.0 %</td>\n",
       "      <td>81.0 %</td>\n",
       "      <td>68.0 %</td>\n",
       "      <td>62.0 %</td>\n",
       "      <td>82.0 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token의 수 n개 이상  Token의 수 n개 이하      경제      기업      사회      국제     부동산  \\\n",
       "0              50             100  46.0 %  36.0 %  75.0 %  50.0 %  75.0 %   \n",
       "1             100             300  43.0 %  53.0 %  76.0 %  80.0 %  84.0 %   \n",
       "2             300             500  42.0 %  57.0 %  73.0 %  77.0 %  86.0 %   \n",
       "3             500           10000  44.0 %  54.0 %  75.0 %  70.0 %  87.0 %   \n",
       "\n",
       "       증권      정치    IT과학      문화  \n",
       "0  92.0 %  60.0 %  31.0 %  71.0 %  \n",
       "1  80.0 %  70.0 %  63.0 %  81.0 %  \n",
       "2  82.0 %  70.0 %  65.0 %  83.0 %  \n",
       "3  81.0 %  68.0 %  62.0 %  82.0 %  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(store_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree 모델은 feature들이 각각 의미있는 변수들이면서, 독립적으로 사용될 수 있을 때 유용한 방법이다.\n",
    "\n",
    "\n",
    "각 변수별로 적절한 기준선을 찾아 공간을 나누기 때문.\n",
    "\n",
    "따라서 Doc2Vec과 같이 좌표평면상에서 벡터의 위치가 아무런 의미가 없는 경우, 학습 효과가 현저하게 떨어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.84\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy : ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.91\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,  n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "print('Accuracy : ', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = np.array(X_train).astype('float32')\n",
    "y_train_nn = pd.get_dummies(y_train).values.astype('float32')\n",
    "\n",
    "\n",
    "X_test_nn = np.array(X_test).astype('float32')\n",
    "y_test_nn = pd.get_dummies(y_test).values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19876, 100) (19876, 2) (200, 100) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_nn.shape, y_train_nn.shape, X_test_nn.shape, y_test_nn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset graphs\n",
    "tf.reset_default_graph() \n",
    "\n",
    "# mini-batches\n",
    "batch_size = X_train_nn.shape[0] // 5\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_nn, y_train_nn))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "# building placeholder\n",
    "X = tf.placeholder(tf.float32, shape = [None, nlp.Doc2Vec_model.vector_size])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, n_class])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# building layers\n",
    "n_neuron = 100\n",
    "\n",
    "W1 = tf.get_variable('W1', shape = ([nlp.Doc2Vec_model.vector_size, n_neuron]), initializer = tf.contrib.layers.xavier_initializer())\n",
    "W2 = tf.get_variable('W2', shape = ([n_neuron, n_neuron]), initializer = tf.contrib.layers.xavier_initializer())\n",
    "W3 = tf.get_variable('W3', shape = ([n_neuron, n_neuron]), initializer = tf.contrib.layers.xavier_initializer())\n",
    "W4 = tf.get_variable('W4', shape = ([n_neuron, n_neuron]), initializer = tf.contrib.layers.xavier_initializer())\n",
    "W5 = tf.get_variable('W5', shape = ([n_neuron, n_class]), initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([n_neuron]))\n",
    "b2 = tf.Variable(tf.random_normal([n_neuron]))\n",
    "b3 = tf.Variable(tf.random_normal([n_neuron]))\n",
    "b4 = tf.Variable(tf.random_normal([n_neuron]))\n",
    "b5 = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "L2 = tf.nn.relu(tf.matmul(L1,W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "L3 = tf.nn.relu(tf.matmul(L2,W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "L4 = tf.nn.relu(tf.matmul(L3,W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "logit = tf.matmul(L4,W5) + b5\n",
    "hypothesis = tf.nn.softmax(tf.matmul(L4,W5) + b5)\n",
    "\n",
    "\n",
    "# cost : cross - entropy cost \n",
    "lamb = 0.0001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, labels = Y)) + lamb * tf.reduce_sum(tf.square(W5))\n",
    "\n",
    "# optimize\n",
    "learning_rate = 0.0001\n",
    "train = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "# prediction\n",
    "prediction = tf.argmax(hypothesis,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(Y,1), prediction), dtype= tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "# restore results\n",
    "train_cost_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "test_cost_list = []\n",
    "test_acc_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **mini-batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict = {X: X_train, Y: y_train}\n",
    "test_dict = {X: X_test_nn, Y: y_test_nn, keep_prob : 1}\n",
    "\n",
    "training_epochs = 1500\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "f, l = iterator.get_next()\n",
    "\n",
    "# launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        # iterator initialize\n",
    "        sess.run(iterator.initializer)\n",
    "        avg_cost = 0\n",
    "\n",
    "        while True:\n",
    "            # mini-batch\n",
    "            try:\n",
    "                batch_x,  batch_y = sess.run([f, l])\n",
    "                feed_dict = {X : batch_x, Y: batch_y, keep_prob : 0.7}\n",
    "                \n",
    "                c, _ = sess.run([cost, train], feed_dict = feed_dict)\n",
    "                avg_cost += c\n",
    "            \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "        \n",
    "        acc, _, test_cost = sess.run([accuracy, prediction, cost], feed_dict = test_dict)\n",
    "        \n",
    "        train_cost_list.append(avg_cost)\n",
    "        test_cost_list.append(test_cost)\n",
    "            \n",
    "        if (epoch+1) % (100) == 0 :\n",
    "            \n",
    "            test_acc_list.append(acc)\n",
    "            \n",
    "            print('Epoch : %s'%(epoch+1), 'cost :',test_cost)\n",
    "            print('Accuracy :', acc)\n",
    "            \n",
    "        \n",
    "    \n",
    "    acc, y_pred, test_cost = sess.run([accuracy, prediction, cost], feed_dict = test_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(train_cost_list, label = 'train_cost')\n",
    "plt.plot(test_cost_list, label = 'test_cost')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **full-batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dict = {X: X_train, Y: y_train}\n",
    "test_dict = {X: X_test_nn, Y: y_test_nn, keep_prob : 1}\n",
    "\n",
    "training_epochs = 1000\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "f, l = iterator.get_next()\n",
    "\n",
    "# launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        # iterator initialize\n",
    "        avg_cost = 0\n",
    "\n",
    "        while True:\n",
    "            # mini-batch\n",
    "            try:\n",
    "                feed_dict = {X : X_train_nn, Y: y_train_nn, keep_prob : 0.7}\n",
    "                \n",
    "                c, _ = sess.run([cost, train], feed_dict = feed_dict)\n",
    "                avg_cost += c\n",
    "            \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "        \n",
    "        acc, y_pred, test_cost = sess.run([accuracy, prediction, cost], feed_dict = test_dict)\n",
    "        \n",
    "        train_cost_list.append(avg_cost)\n",
    "        test_cost_list.append(test_cost)\n",
    "            \n",
    "        if (epoch+1) % (100) == 0 :\n",
    "            \n",
    "            test_acc_list.append(acc)\n",
    "            \n",
    "            print('Epoch : %s'%(epoch+1), 'cost :',test_cost)\n",
    "            print('Accuracy :', acc)\n",
    "        #print(sess.run(tf.confusion_matrix(labels = tf.reshape(Y, [-1]), predictions = tf.reshape(y_pred, [-1])), feed_dict = test_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(train_cost_list, label = 'train_cost')\n",
    "plt.plot(test_cost_list, label = 'test_cost')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fininsight_python_3.5",
   "language": "python",
   "name": "fininsight_python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
