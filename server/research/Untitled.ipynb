{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ko_text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_file, usecols = ''):\n",
    "    print('==================================================')\n",
    "    print('Data Loading : %s'%path_to_file)\n",
    "    try:\n",
    "        if usecols:\n",
    "            data = pd.read_csv(open(path_to_file,'r'), encoding='utf-8', engine='c', usecols = usecols)\n",
    "        else:\n",
    "            data = pd.read_csv(open(path_to_file,'r'), encoding='utf-8', engine='c')\n",
    "        # Token 칼럼이 존재하는 경우\n",
    "        if 'Token' in data.columns:\n",
    "            # 용량을 줄이기 위해 '단어 단어' 꼴로 묶어둔 token을 ['단어', '단어']의 리스트 형태로 풀기\n",
    "            data['Token'] = [token.split() for token in data['Token']]\n",
    "        print('Data Loaded')\n",
    "\n",
    "        return data\n",
    "\n",
    "    except:\n",
    "        print('%s가 존재하지 않습니다.'%path_to_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Data Loading : ../data/data_merged.csv\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "temp_df = load_data('../data/data_merged.csv', usecols = ['Section','Token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 모델을 성공적으로 불러왔습니다.\n"
     ]
    }
   ],
   "source": [
    "nlp = NLP()\n",
    "d2v = D2V('../Doc2Vec_model/Doc2Vec_dm=True&cc=6442&vs=100&win=5&min=1&sample=0.0001&epochs=10&dm_mean=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ls = temp_df['Token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocessing_queue_put(func, queue, **kwargs):\n",
    "    queue.put(func(**kwargs))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('../Doc2Vec_model/Doc2Vec_dm=True&cc=6442&vs=100&win=5&min=1&sample=0.0001&epochs=10&dm_mean=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vectors_multiprocessing(doc_ls):\n",
    "    queue_ls = []\n",
    "    procs = []\n",
    "    result_ls = []\n",
    "    batch_size = len(doc_ls) // 10\n",
    "    \n",
    "    # process에 작업들을 할당\n",
    "    for i, idx in enumerate(range(0, len(token_ls), batch_size)):\n",
    "        try:\n",
    "            batch_link_map = token_ls[idx : idx + batch_size]\n",
    "        except:\n",
    "            batch_link_map = token_ls[idx :]\n",
    "\n",
    "        queue_ls.append(Queue())\n",
    "        proc = Process(\n",
    "                target= multiprocessing_queue_put,\n",
    "                kwargs = {\n",
    "                    'func' : d2v.infer_vectors_with_Doc2Vec,\n",
    "                    'queue' : queue_ls[i],\n",
    "                    'doc_ls' : batch_link_map})\n",
    "\n",
    "        procs.append(proc)    \n",
    "        proc.start()\n",
    "\n",
    "    for queue in queue_ls:\n",
    "        temp_result_ls = queue.get()\n",
    "        queue.close()\n",
    "        del queue\n",
    "\n",
    "        result_ls += temp_result_ls\n",
    "\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "        del proc\n",
    "\n",
    "    return result_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 ms, sys: 93.5 ms, total: 145 ms\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_ls = infer_vectors_multiprocessing(token_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.7 s, sys: 24.7 ms, total: 58.8 s\n",
      "Wall time: 58.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_ls = d2v.infer_vectors_with_Doc2Vec(token_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6442"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_args_kwargs(arg1, arg2, arg3):\n",
    "        print (\"인자1:\", arg1)\n",
    "        print (\"인자2:\", arg2)\n",
    "        print (\"인자3:\", arg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인자1: 5\n",
      "인자2: two\n",
      "인자3: 3\n"
     ]
    }
   ],
   "source": [
    "# 이제 **kwargs:\n",
    "kwargs = {\"arg3\": 3, \"arg2\": \"two\", \"arg1\": 5} # arg(숫자)는 위 함수의 인자의 이름과 같아야합니다.\n",
    "test_args_kwargs(**kwargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fininsight_python_3.5",
   "language": "python",
   "name": "fininsight_python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
